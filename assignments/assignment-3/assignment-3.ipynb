{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "\n",
    "## Instructions \n",
    "For full credit, earn 100 points. __Problem C__ is big, and worth 100 points on its own, with its own bonus questions. __Problem A__ and __Problem B__ are worth 35 and 25 respectively, so full credit requires significant progress on __Problem C__, but __Problem A__ and __Problem B__ are more closed-ended, i.e., likely can be finished more quickly. Please indicate clearly which components of the assignment are completed as you fill out your solution and turn it in.\n",
    "\n",
    "## Problem A _(35 points)_\n",
    "For this problem, you will be working with [flight data from the Bureau of Transporttaion Statistics](http://stat-computing.org/dataexpo/2009/the-data.html). For development, these data are a little largeish (~700Mb/7 million flights) for prototyping, so two truncated files are provided under `data/2007-10k.csv` and `data/2008-10k.csv`. __Important: it's strongly recommended to prototype and develop code using the truncated data.__\n",
    "\n",
    "__Design note:__ The code you will develop as part of this problem's solution should be generalized so that it works when there are more than just two years' worth of data, i.e. when there are more files than just `2007.csv` and `2008.csv`.\n",
    "\n",
    "__To work with the full dataset,__ go to the link and download the data files for 2007 and 2008.  Put these files in the `data/` directory and extract them. (The files can be extracted from the command line by navigating into `data/` and running `bunzip2 200{7..8}.csv.bz2`.\n",
    "\n",
    "__A1.__ _(5 points)_ Write a function that takes a year as an input argument and loads the data for that year into a `pandas` dataframe, then drops the rows in the dataframe that have a null in any of these columns: \"Year\", \"Month\", \"DayofMonth\", \"DepTime\", \"Origin\", and \"Dest\", and then returns this dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A2.__ _(10 points)_ Update the function so that before returning the dataframe, it creates a new column in the dataframe that contains `datetime` objects holding the departure date of the flight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A3.__ _(5 points)_ Update the function so that it also takes an airport code as an input argument, and returns a dataframe of flights originating from that airport that occurred in the specified year. \\[__Hint__: while prototyping, to test your code choose an `'Origin'` that's in the truncated file, like  Philly's airport!\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A4.__ _(5 points)_ Using this function, create dataframes holding the flight data for Philadelphia International Airport (PHL) for 2007 and 2008. Then use the `.groupby()` method to obtain the busiest month of the year for both years. Did this change from 2007 to 2008? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A5.__ _(10 points)_ Update the function so that instead of a year value, it now takes two dates as input, denoting a range. The function must now return all flights originating from the specified airport within this range of time. If the range spans multiple years, the function should load data from all necessary files and return a single dataframe containing all the data within the specified range of time.\n",
    "\n",
    "Using this function, get all the flight data for flights from PHL for all of 2007 and 2008. Then, create a daily count of flights over all of the days in the two years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__BONUS.__ _(5 points)_ Display the daily counts in a plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem B _(25 points)_\n",
    "\n",
    "In this problem, you will be using the [Baseball Databank provided by Sean Lahman](http://seanlahman.com/baseball-archive/statistics/). This data is already in the `data/baseballdatabank2017.1/core/` directory. It contains a collection of tables. The immediate goal will be to create a dataframe that has the following information for each baseball player:\n",
    "\n",
    "- Batting statistics (to be described)\n",
    "- Fielding statistics (to be described)\n",
    "- Pitching statistics (to be described)\n",
    "- Their salaries\n",
    "- The teams they played for\n",
    "- Their full names: First Middle Last\n",
    "- Their heights and weights\n",
    "\n",
    "The dataset has a data dictionary available at:\n",
    "\n",
    "- `../data/baseballdatabank-2017.1/core/readme2014.txt`\n",
    "\n",
    "The data and tables you will need are:\n",
    "\n",
    "- `Batting.csv`\n",
    "    - The number of games played and at bats\n",
    "    - The number of runs, hits, doubles, triples, homeruns, RBIs, strikeouts, and times hit by\n",
    "- `Fielding.csv`\n",
    "    - The number of games played\n",
    "    - The number of opponents put out, assisted outs, and fielding errors\n",
    "- `Master.csv`\n",
    "    - Their full names\n",
    "    - Their heights and weights\n",
    "- `Pitching.csv`\n",
    "    - The number of games played, won, lost\n",
    "    - The number of strikeouts, hits, earned runs, homeruns, and batters hit by pitches   \n",
    "- `Salaries.csv`\n",
    "    - The players salary\n",
    "- `Teams.csv`\n",
    "    - The name of the player's team\n",
    "    - The year the team was named its name\n",
    "    \n",
    "__B1.__ _(5 points)_ Load the data and keep only the columns of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B2.__ _(5 points)_ Create a function that takes a year as input and outputs subsets of each of the tables with data from only that year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B3.__ _(10 points)_ Write a new function that will again take a year as input, then use the previous filtering function to get separate tables, and finally merge these tables using the appropriate joins. Determine which columns have the same names but different values, then determine a useful naming scheme of suffixes that indicates the table the column was originally drawn from. Use this scheme in combination with the `suffixes` argument of the `merge()` function to avoid column name conflicts. Also remove duplicate columns from the merged table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B4.__ _(5 points)_ There will be nulls in the data. Determine how to deal with the NAs and apply this strategy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem C _(100 points)_\n",
    "\n",
    "In this exercise we'll build and expand a cheese and wine pairings database with the high-level goal of linking wine varieties and recipe ingredients.\n",
    "\n",
    "A Google search on food and wine pairings turned up a literature Ph.D. candidate's blog post:\n",
    "+ http://sedimentality.com/drinking-wine/list-of-wine-and-food-pairings/\n",
    "\n",
    "This post is interesting, because instead of pairing dishes with wine vintages or brands, it pairs ingredients with wine varieties, tagging ingredients by several categories. Thus, we could pull the data from this website to join wine varieties from a large wine reviews database to ingredients in a large recipes database. Your goal in this section of the assignment is to collect the ingredient-variety-category data.\n",
    "\n",
    "__C1.__ _(5/5 pts)_ Why are we allowed to scrape this data out of the website?\n",
    "\n",
    "Explain what information is posted (or not posted) on this domain, allowing us to definitely move forward with this exercise. Use the markdown cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Response._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C2.__ _(5/10 pts)_ Download the blog post using the `requests` module and store the html response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C3.__ _(5/15 pts)_ Navigate to the same URL in your web browser, and identify where the target data are by inspecting the html (with your eyes) and matching up tags with the target content.\n",
    "\n",
    "In the markdown cell below, describe the tags that you will need to extract the data from. Provide as much information as is necessary on the nesting of the document so as to be able to describe the location of the target data for parsing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Response._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C4.__ _(10/25 pts)_ Parse the html text with BeautifulSoup in preparation for scraping. Then, print out the target data. \\[__Hint__: use `BeautifulSoup`'s `.find_all(tag_list)` method to iterate through the tags identified in __C3__. From there, check to see if a tag has the data of interest by using the `.find(tag)` method. \\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C5.__ _(5/30 pts)_ Interpret the output from the previous part to make a plan for how to split the target data up with regular expressions to create a structured data object. Describe any structure that you'll use in the markdown cell, below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Response._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C6.__ _(5/35 pts)_ Create an associative array (dictionary) data structure that can hold the ingredients in their categories, by wine variety. Use a default dictionary with its default value as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C7.__ _(10/45 pts)_ Complete the web-scraping script's loop in __C4__ and store the extracted data in the data structure you initialized in __C6__. Print the stored data to confirm your output. Note you'll need to use the regular expresions module to complete this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C8.__ _(5/50 pts)_ Write your data out to a json file. Name this file: `./data/wine_ingredient-pairings.json`.\n",
    "\n",
    "Note: since `defaultdicts` are not json serialiable (you can't make a file out of them), you will have to coerce (type cast) your final data to a standard Python dictionary to finish the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C9.__ _(5/55 pts)_ What limitations did you observe in this data, and in your extraction of this data?\n",
    "\n",
    "Were there any issues either with this data's content, volume, its veracity or accuracy? Were you able to get all of the data present? Did you wind up getting some data that you didn't want or need, or maybe not in the right form? Take a look at the wine and categories keysâ€”are they consistent? Be as specific as possible!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Response._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__BONUS__ _(5 pts)_ Supposing we were going to rebuild the scraped wine-food pairings data as a gold standard through a survey. Are there any changes to allowable food types or to the manner in which the data are organized that might be beneficial to the wine recommendation task?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Response._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C10.__ _(5/60 pts)_ Download and familiarize yourself with the cuisine prediction dataset: https://www.kaggle.com/kaggle/recipe-ingredients-dataset (it's only necessary to download the `train.json` file and work with that).\n",
    "We're going to enrich our current data by adding results from this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C11.__ _(15/75 pts)_ Expand each wine variety's list of foods to include any co-appearing in the recipes found in the above Kaggle dataset. Make sure to record how often ingredients in the Kaggle recipes occured alongside foods in the wine variety list. Store this information in another nested `defaultdict`, with the following structure:\n",
    "\n",
    "```\n",
    "wines = {\n",
    "    wine: {\n",
    "        food_category: {\n",
    "            pairing: Counter(),\n",
    "            ...\n",
    "        },\n",
    "        ...\n",
    "    },\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__BONUS.__ _(5 pts)_ How would you create the above structure for `wines` using nested a nested `defaultdict`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C12.__ _(10/90 pts)_ We'd also like to incorporate a wine review dataset. Download and familiarize yourself with the dataset, found at: https://www.kaggle.com/zynicide/wine-reviews. Specifically, utilize the file: `winemag-data-130k-v2.csv` to link each of the scraped wines found in `wines` to the specific names of the wines which are of that variety (i.e., for the Sauvignon wine, create a list of all the wines with `variety` column that say Sauvignon, and attach them to the `wines` object from before)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C13.__ _(5/95 pts)_ Now write a function which allows the user to input a list of ingredients and also a choice of ingredient category (such as \"Cheese/nuts\"), and outputs a list of all wine names that pair with these ingredients. This function won't incorporate the additional ingredients we obtained from the Kaggle dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C14.__ _(5/100 pts)_ This should give you a ton of results! Maybe too many for the function to actually be useful in helping pick a wine. Perhaps there's some disagreement between the datasets. How should the `pairing`s and `ingredient`s from the scraped data and the Kaggle data each individually be pre-processed as text to obtain a good alignment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Response._"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
